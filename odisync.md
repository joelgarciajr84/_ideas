Ã‰pico: ComparaÃ§Ã£o e envio de diffs entre arquivos JSON de buckets S3
ðŸ§ª HistÃ³ria 1: Como engenheiro de dados, quero um Glue Job que compare arquivos JSON de dois buckets (ontem e hoje), para identificar e salvar as diferenÃ§as entre eles.
CritÃ©rios de AceitaÃ§Ã£o:

O Glue Job deve ler arquivos JSON dos buckets bucket_ontem/ e bucket_hoje/ (parametrizÃ¡veis).

A comparaÃ§Ã£o deve ocorrer por chave Ãºnica presente nos arquivos.

As diferenÃ§as devem ser salvas como arquivos JSON no bucket bucket_diffs/YYYY-MM-DD/.

O job deve rodar de forma parametrizada com a data do dia atual (ex: via trigger, step function, etc).

Tarefas TÃ©cnicas:

 Criar script PySpark para comparar os dados.

 Criar Glue Job com IAM Role apropriada.

 Configurar trigger/evento para execuÃ§Ã£o diÃ¡ria (pode ser por agendamento ou manual).

ðŸ“¤ HistÃ³ria 2: Como engenheiro de plataforma, quero que cada novo arquivo salvo no bucket de diffs envie uma mensagem a uma fila SQS, para processamentos posteriores.
CritÃ©rios de AceitaÃ§Ã£o:

Cada novo arquivo no bucket_diffs/YYYY-MM-DD/ deve gerar uma mensagem na fila SQS.

A mensagem deve conter no mÃ­nimo o path do arquivo salvo e a data.

O bucket de diffs deve ter notificaÃ§Ã£o configurada para a fila SQS.

A fila deve ser criada com polÃ­ticas apropriadas de acesso.

Tarefas TÃ©cnicas:

 Criar bucket de diffs com configuraÃ§Ã£o de evento S3 â†’ SQS.

 Criar fila SQS com permissÃµes adequadas.

 Configurar notificaÃ§Ã£o de evento no bucket.

â° HistÃ³ria 3: Como engenheiro de dados, quero um ECS Task agendado diariamente Ã s 2h que leia os arquivos de diffs do dia atual e envie os eventos para um tÃ³pico Kafka.
CritÃ©rios de AceitaÃ§Ã£o:

ECS Task deve ser agendada via EventBridge para execuÃ§Ã£o diÃ¡ria Ã s 2h da manhÃ£.

O container deve ler os arquivos do path bucket_diffs/YYYY-MM-DD/.

Cada arquivo deve ser lido e seu conteÃºdo publicado em um tÃ³pico Kafka.

O tÃ³pico Kafka e credenciais de acesso devem ser configurÃ¡veis.

Tarefas TÃ©cnicas:

 Criar imagem Docker que lÃª do S3 e envia para Kafka.

 Criar cluster ECS (ou usar existente).

 Criar ECS Task Definition e EventBridge Rule.

 Garantir que o task tenha acesso ao S3 e Kafka.




 infra


 Infraestrutura Glue + Buckets
 Criar dois buckets S3: bucket_hoje e bucket_ontem (parametrizÃ¡veis).

 Criar bucket bucket_diffs para armazenar os diffs diÃ¡rios.

 Criar Glue Job:

 Criar IAM Role para o Glue Job com permissÃµes nos trÃªs buckets.

 Criar script inicial (mesmo que placeholder) e apontar no Glue Job.

 (Opcional) Criar trigger diÃ¡ria no Glue (ou Step Function) para rodar o job com a data do dia.

ðŸ“© Infraestrutura S3 + SQS
 Criar fila SQS diffs-events-queue.

 Criar polÃ­tica de acesso S3 â†’ SQS (bucket pode publicar na fila).

 Configurar notificaÃ§Ã£o no bucket_diffs para que eventos PUT de arquivos disparem mensagens para a fila SQS.

ðŸ³ Infraestrutura ECS + EventBridge
 Criar cluster ECS (ou referenciar um existente).

 Criar Task Definition com:

Imagem Docker (pode ser uma imagem dummy atÃ© o app estar pronto).

IAM Role para acesso ao S3 e ao Kafka.

 Criar EventBridge Rule para agendamento diÃ¡rio Ã s 2h da manhÃ£.

 Criar log group (CloudWatch) para os logs da task.

ðŸ” IAM e SeguranÃ§a
 IAM Role para Glue Job (acesso a S3).

 IAM Role para ECS Task (acesso a S3 e Kafka endpoint/secret).

 Policies necessÃ¡rias para o S3 publicar na SQS.

 VariÃ¡veis sensÃ­veis como secrets para Kafka (usando Secrets Manager ou variÃ¡vel de ambiente segura).

ðŸ“¦ (Opcional) Observabilidade & Alertas
 Habilitar logging nos buckets S3.

 CloudWatch Logs para Glue e ECS.

 (Opcional) Alarme de falha na execuÃ§Ã£o do ECS Task (ex: erro > 0).




√âpico: Compara√ß√£o e envio de diffs entre arquivos JSON de buckets S3
üß™ Hist√≥ria 1: Como engenheiro de dados, quero um Glue Job que compare arquivos JSON de dois buckets (ontem e hoje), para identificar e salvar as diferen√ßas entre eles.
Crit√©rios de Aceita√ß√£o:

O Glue Job deve ler arquivos JSON dos buckets bucket_ontem/ e bucket_hoje/ (parametriz√°veis).

A compara√ß√£o deve ocorrer por chave √∫nica presente nos arquivos.

As diferen√ßas devem ser salvas como arquivos JSON no bucket bucket_diffs/YYYY-MM-DD/.

O job deve rodar de forma parametrizada com a data do dia atual (ex: via trigger, step function, etc).

Tarefas T√©cnicas:

 Criar script PySpark para comparar os dados.

 Criar Glue Job com IAM Role apropriada.

 Configurar trigger/evento para execu√ß√£o di√°ria (pode ser por agendamento ou manual).

üì§ Hist√≥ria 2: Como engenheiro de plataforma, quero que cada novo arquivo salvo no bucket de diffs envie uma mensagem a uma fila SQS, para processamentos posteriores.
Crit√©rios de Aceita√ß√£o:

Cada novo arquivo no bucket_diffs/YYYY-MM-DD/ deve gerar uma mensagem na fila SQS.

A mensagem deve conter no m√≠nimo o path do arquivo salvo e a data.

O bucket de diffs deve ter notifica√ß√£o configurada para a fila SQS.

A fila deve ser criada com pol√≠ticas apropriadas de acesso.

Tarefas T√©cnicas:

 Criar bucket de diffs com configura√ß√£o de evento S3 ‚Üí SQS.

 Criar fila SQS com permiss√µes adequadas.

 Configurar notifica√ß√£o de evento no bucket.

‚è∞ Hist√≥ria 3: Como engenheiro de dados, quero um ECS Task agendado diariamente √†s 2h que leia os arquivos de diffs do dia atual e envie os eventos para um t√≥pico Kafka.
Crit√©rios de Aceita√ß√£o:

ECS Task deve ser agendada via EventBridge para execu√ß√£o di√°ria √†s 2h da manh√£.

O container deve ler os arquivos do path bucket_diffs/YYYY-MM-DD/.

Cada arquivo deve ser lido e seu conte√∫do publicado em um t√≥pico Kafka.

O t√≥pico Kafka e credenciais de acesso devem ser configur√°veis.

Tarefas T√©cnicas:

 Criar imagem Docker que l√™ do S3 e envia para Kafka.

 Criar cluster ECS (ou usar existente).

 Criar ECS Task Definition e EventBridge Rule.

 Garantir que o task tenha acesso ao S3 e Kafka.

